{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import scipy.special as sc\n",
        "from scipy.stats import chi2\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "@torch.no_grad()\n",
        "def _invSqrt(A):\n",
        "        vals, vecs = torch.linalg.eigh(A)\n",
        "        return vecs @ torch.diag(1.0 / torch.sqrt(vals)) @ vecs.T\n",
        "\n",
        "@torch.no_grad()\n",
        "def rTensorNorm(n, M, Sigma1, Sigma2, Sigma3):\n",
        "    p1 = Sigma1.shape[0]\n",
        "    p2 = Sigma2.shape[0]\n",
        "    p3 = Sigma3.shape[0]\n",
        "    e1_vals, e1_vecs = torch.linalg.eigh(Sigma1)\n",
        "    sqrtSigma1 = e1_vecs @ torch.diag(torch.sqrt(e1_vals)) @ e1_vecs.T\n",
        "    e2_vals, e2_vecs = torch.linalg.eigh(Sigma2)\n",
        "    sqrtSigma2 = e2_vecs @ torch.diag(torch.sqrt(e2_vals)) @ e2_vecs.T\n",
        "    e3_vals, e3_vecs = torch.linalg.eigh(Sigma3)\n",
        "    sqrtSigma3 = e3_vecs @ torch.diag(torch.sqrt(e3_vals)) @ e3_vecs.T\n",
        "    Z = torch.randn(n, p1, p2, p3, device=device)\n",
        "    Z = Z.view(n * p1 * p2, p3) @ sqrtSigma3\n",
        "    Z = Z.view(n, p1, p2, p3)\n",
        "    Z = Z.permute(0, 1, 3, 2).contiguous()\n",
        "    Z = Z.view(n * p1 * p3, p2) @ sqrtSigma2\n",
        "    Z = Z.view(n, p1, p3, p2)\n",
        "    Z = Z.permute(0, 3, 2, 1).contiguous()\n",
        "    Z = Z.view(n * p2 * p3, p1) @ sqrtSigma1\n",
        "    Z = Z.view(n, p2, p3, p1)\n",
        "    Z = Z.permute(0, 3, 1, 2).contiguous()\n",
        "    M_expanded = M.unsqueeze(0).expand(n, p1, p2, p3)\n",
        "    Z = Z + M_expanded\n",
        "    return Z\n",
        "\n",
        "@torch.no_grad()\n",
        "def computeTensorMD(C, invSqrt1, invSqrt2, invSqrt3, returnContributions=False):\n",
        "    n, p1, p2, p3 = C.shape\n",
        "    C = C.view(n * p1 * p2, p3) @ invSqrt3\n",
        "    C = C.view(n, p1, p2, p3)\n",
        "    C = C.permute(0, 1, 3, 2).contiguous()\n",
        "    C = C.view(n * p1 * p3, p2) @ invSqrt2\n",
        "    C = C.view(n, p1, p3, p2)\n",
        "    C = C.permute(0, 3, 2, 1).contiguous()\n",
        "    C = C.view(n * p2 * p3, p1) @ invSqrt1\n",
        "    C = C.view(n, p2, p3, p1)\n",
        "    C = C.permute(0, 3, 1, 2).contiguous()\n",
        "    D = C * C\n",
        "    D = D.view(n, -1)\n",
        "    TMDsq = D.sum(dim=1)\n",
        "    if returnContributions:\n",
        "        D = D.view(n, p1, p2, p3)\n",
        "        return TMDsq, D\n",
        "    else:\n",
        "        return TMDsq\n",
        "\n",
        "@torch.no_grad()\n",
        "def updateOneCov(C, invSqrt2, invSqrt3):\n",
        "    n, p1, p2, p3 = C.shape\n",
        "    C = C.view(n * p1 * p2, p3) @ invSqrt3\n",
        "    C = C.view(n, p1, p2, p3)\n",
        "    C = C.permute(0, 1, 3, 2).contiguous()\n",
        "    C = C.view(n * p1 * p3, p2) @ invSqrt2\n",
        "    C = C.view(n, p1, p3, p2)\n",
        "    C = C.permute(1, 0, 3, 2).contiguous()\n",
        "    C = C.view(p1, n * p2 * p3)\n",
        "    Sigma1 = (C @ C.T) / (n * p2 * p3)\n",
        "    return Sigma1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def flipFlopMLE(C1, C2, C3,\n",
        "                Sigma1init, Sigma2init, Sigma3init,\n",
        "                invSqrt2init, invSqrt3init,\n",
        "                maxIter,\n",
        "                tol):\n",
        "\n",
        "    old1 = Sigma1init\n",
        "    old2 = Sigma2init\n",
        "    old3 = Sigma3init\n",
        "    invSqrt2 = invSqrt2init\n",
        "    invSqrt3 = invSqrt3init\n",
        "    for it in range(maxIter):\n",
        "        Sigma1 = updateOneCov(C1, invSqrt2, invSqrt3)\n",
        "        invSqrt1 = _invSqrt(Sigma1)\n",
        "        Sigma2 = updateOneCov(C2, invSqrt3, invSqrt1)\n",
        "        invSqrt2 = _invSqrt(Sigma2)\n",
        "        Sigma3 = updateOneCov(C3, invSqrt1, invSqrt2)\n",
        "        d11_1 = Sigma1[0, 0]\n",
        "        d11_2 = Sigma2[0, 0]\n",
        "        Sigma1 = Sigma1 / d11_1\n",
        "        Sigma2 = Sigma2 / d11_2\n",
        "        Sigma3 = Sigma3 * (d11_1 * d11_2)\n",
        "        if it == maxIter - 1:\n",
        "            break\n",
        "        frobDiff = torch.sum((Sigma1 - old1) ** 2) \\\n",
        "                 + torch.sum((Sigma2 - old2) ** 2) \\\n",
        "                 + torch.sum((Sigma3 - old3) ** 2)\n",
        "        if frobDiff < tol:\n",
        "            break\n",
        "        invSqrt3 = _invSqrt(Sigma3)\n",
        "        old1 = Sigma1\n",
        "        old2 = Sigma2\n",
        "        old3 = Sigma3\n",
        "    return {\n",
        "        \"Sigma1\": Sigma1,\n",
        "        \"Sigma2\": Sigma2,\n",
        "        \"Sigma3\": Sigma3,\n",
        "        \"invSqrt1\": invSqrt1,\n",
        "        \"invSqrt2\": invSqrt2\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def cStep(X, C, Sigma1, Sigma2, Sigma3,\n",
        "          invSqrt1, invSqrt2, invSqrt3,\n",
        "          alpha,\n",
        "          maxIterC,\n",
        "          tolC,\n",
        "          maxIterFF,\n",
        "          tolFF):\n",
        "    def _ld(S1, S2, S3):\n",
        "        return (p2 * p3) * torch.logdet(S1) \\\n",
        "             + (p1 * p3) * torch.logdet(S2) \\\n",
        "             + (p1 * p2) * torch.logdet(S3)\n",
        "    n, p1, p2, p3 = X.shape\n",
        "    h = int(math.floor(alpha * n))\n",
        "    ldOld = _ld(Sigma1, Sigma2, Sigma3)\n",
        "    for it in range(maxIterC):\n",
        "        TMDsAll = computeTensorMD(C, invSqrt1, invSqrt2, invSqrt3)\n",
        "        sortedIdx = torch.argsort(TMDsAll)\n",
        "        subsetIndices = sortedIdx[:h]\n",
        "        Xsub = X[subsetIndices]\n",
        "        subMean = Xsub.mean(dim=0)\n",
        "        C1 = Xsub - subMean\n",
        "        C2 = C1.permute(0, 2, 3, 1).contiguous()\n",
        "        C3 = C1.permute(0, 3, 1, 2).contiguous()\n",
        "        initFF = flipFlopMLE(\n",
        "            C1, C2, C3,\n",
        "            Sigma1, Sigma2, Sigma3,\n",
        "            invSqrt2, invSqrt3,\n",
        "            maxIterFF,\n",
        "            tolFF\n",
        "        )\n",
        "        Sigma1 = initFF[\"Sigma1\"]\n",
        "        Sigma2 = initFF[\"Sigma2\"]\n",
        "        Sigma3 = initFF[\"Sigma3\"]\n",
        "        invSqrt1 = initFF[\"invSqrt1\"]\n",
        "        invSqrt2 = initFF[\"invSqrt2\"]\n",
        "        ldNew = _ld(Sigma1, Sigma2, Sigma3)\n",
        "        if it == maxIterC - 1 or abs(ldNew - ldOld) < tolC:\n",
        "            break\n",
        "        ldOld = ldNew\n",
        "        C = X - subMean\n",
        "        vals, vecs = torch.linalg.eigh(Sigma3)\n",
        "        invSqrt3 = vecs @ torch.diag(1.0 / torch.sqrt(vals)) @ vecs.T\n",
        "    return {\n",
        "        \"Sigma1\": Sigma1,\n",
        "        \"Sigma2\": Sigma2,\n",
        "        \"Sigma3\": Sigma3,\n",
        "        \"invSqrt1\": invSqrt1,\n",
        "        \"invSqrt2\": invSqrt2,\n",
        "        \"subsetIndices\": subsetIndices,\n",
        "        \"TMDsAll\": TMDsAll,\n",
        "        \"ld\": ldNew\n",
        "    }\n",
        "\n",
        "@torch.no_grad()\n",
        "def tmcd(X,\n",
        "         alpha,\n",
        "         nSubsets,\n",
        "         nBest,\n",
        "         maxIterCshort,\n",
        "         maxIterFFshort,\n",
        "         maxIterCfull,\n",
        "         maxIterFFfull,\n",
        "         tolC,\n",
        "         tolFF,\n",
        "         beta):\n",
        "\n",
        "    n, p1, p2, p3 = X.shape\n",
        "    s = int(math.ceil(p1/(p2*p3) + p2/(p1*p3) + p3/(p1*p2))) + 2\n",
        "    allSubsets = []\n",
        "    for _ in range(nSubsets):\n",
        "        allSubsets.append(torch.randperm(n)[:s].to(device))\n",
        "    shortResults = []\n",
        "    for i in range(nSubsets):\n",
        "        idx = allSubsets[i]\n",
        "        xSub = X[idx]\n",
        "        subMean = xSub.mean(dim=0)\n",
        "        C1 = xSub - subMean\n",
        "        C2 = C1.permute(0, 2, 3, 1).contiguous()\n",
        "        C3 = C1.permute(0, 3, 1, 2).contiguous()\n",
        "        initSig1 = torch.eye(p1, device=device)\n",
        "        initSig2 = torch.eye(p2, device=device)\n",
        "        initSig3 = torch.eye(p3, device=device)\n",
        "        initInvSqrt2 = torch.eye(p2, device=device)\n",
        "        initInvSqrt3 = torch.eye(p3, device=device)\n",
        "        shortMLE = flipFlopMLE(\n",
        "            C1, C2, C3,\n",
        "            initSig1, initSig2, initSig3,\n",
        "            initInvSqrt2, initInvSqrt3,\n",
        "            maxIterFFshort,\n",
        "            tolFF\n",
        "        )\n",
        "        C = X - subMean\n",
        "        curInvSqrt3 = _invSqrt(shortMLE[\"Sigma3\"])\n",
        "        shortRes = cStep(\n",
        "            X, C,\n",
        "            shortMLE[\"Sigma1\"],\n",
        "            shortMLE[\"Sigma2\"],\n",
        "            shortMLE[\"Sigma3\"],\n",
        "            shortMLE[\"invSqrt1\"],\n",
        "            shortMLE[\"invSqrt2\"],\n",
        "            curInvSqrt3,\n",
        "            alpha,\n",
        "            maxIterCshort,\n",
        "            tolC,\n",
        "            maxIterFFshort,\n",
        "            tolFF\n",
        "        )\n",
        "        shortResults.append(shortRes)\n",
        "    allLd = torch.tensor([res[\"ld\"] for res in shortResults], device=device)\n",
        "    rankLd = torch.argsort(allLd)\n",
        "    topIdx = rankLd[:min(nBest, nSubsets)]\n",
        "    fullResults = []\n",
        "    for j in range(len(topIdx)):\n",
        "        chosen = shortResults[topIdx[j]]\n",
        "        xSub = X[chosen[\"subsetIndices\"]]\n",
        "        subMean = xSub.mean(dim=0)\n",
        "        C = X - subMean\n",
        "        invSqrt3 = _invSqrt(chosen[\"Sigma3\"])\n",
        "        fullRes = cStep(\n",
        "            X, C,\n",
        "            chosen[\"Sigma1\"],\n",
        "            chosen[\"Sigma2\"],\n",
        "            chosen[\"Sigma3\"],\n",
        "            chosen[\"invSqrt1\"],\n",
        "            chosen[\"invSqrt2\"],\n",
        "            invSqrt3,\n",
        "            alpha,\n",
        "            maxIterCfull,\n",
        "            tolC,\n",
        "            maxIterFFfull,\n",
        "            tolFF\n",
        "        )\n",
        "        fullResults.append(fullRes)\n",
        "    allLdFull = torch.tensor([r[\"ld\"] for r in fullResults], device=device)\n",
        "    bestFullIdx = torch.argmin(allLdFull)\n",
        "    bestRaw = fullResults[bestFullIdx]\n",
        "    dfMain = p1 * p2 * p3\n",
        "    dfPlus = dfMain + 2\n",
        "    chiAlpha = chi2.ppf(alpha, dfMain)\n",
        "    cdfVal = chi2.cdf(chiAlpha, dfPlus)\n",
        "    gammaAlpha = alpha / cdfVal\n",
        "    S1 = bestRaw[\"Sigma1\"]\n",
        "    S2 = bestRaw[\"Sigma2\"]\n",
        "    S3 = bestRaw[\"Sigma3\"] * gammaAlpha\n",
        "    invSqrt2 = bestRaw[\"invSqrt2\"]\n",
        "    vals3, vecs3 = torch.linalg.eigh(S3)\n",
        "    invSqrt3 = vecs3 @ torch.diag(1.0 / torch.sqrt(vals3)) @ vecs3.T\n",
        "    TMDsqAll = bestRaw[\"TMDsAll\"]\n",
        "    cutoff = chi2.ppf(beta, dfMain)\n",
        "    goodSet = torch.where((TMDsqAll / gammaAlpha) < cutoff)[0]\n",
        "    finalGood = torch.unique(torch.cat([bestRaw[\"subsetIndices\"], goodSet]))\n",
        "    outliers = torch.tensor(list(set(range(n)) - set(finalGood.tolist())), device=device)\n",
        "    Xgood = X[finalGood]\n",
        "    M = Xgood.mean(dim=0)\n",
        "    alphaHat = float(len(finalGood)) / n\n",
        "    C1 = Xgood - M\n",
        "    C2 = C1.permute(0, 2, 3, 1).contiguous()\n",
        "    C3 = C1.permute(0, 3, 1, 2).contiguous()\n",
        "    ffFinal = flipFlopMLE(\n",
        "        C1, C2, C3,\n",
        "        S1, S2, S3,\n",
        "        invSqrt2, invSqrt3,\n",
        "        maxIterFFfull,\n",
        "        tolFF\n",
        "    )\n",
        "    S1 = ffFinal[\"Sigma1\"]\n",
        "    S2 = ffFinal[\"Sigma2\"]\n",
        "    S3 = ffFinal[\"Sigma3\"]\n",
        "    chiAlphaHat = chi2.ppf(alphaHat, dfMain)\n",
        "    cdfValHat = chi2.cdf(chiAlphaHat, dfPlus)\n",
        "    gammaAlphaHat = alphaHat / cdfValHat\n",
        "    S3 = S3 * gammaAlphaHat\n",
        "    return {\n",
        "        \"M\": M,\n",
        "        \"Sigma1\": S1,\n",
        "        \"Sigma2\": S2,\n",
        "        \"Sigma3\": S3,\n",
        "        \"outliers\": outliers,\n",
        "        \"finalGood\": finalGood\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "jnNO1RT7U5vC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def genPositiveDefMat(dim, rangeVar=(0.1, 1.0)):\n",
        "    eta = 1.0\n",
        "    def _rcor_onion(d):\n",
        "        if d == 1:\n",
        "            return torch.ones(1, 1, dtype=torch.double)\n",
        "        if d == 2:\n",
        "            rho = 2 * torch.distributions.Beta(eta, eta).sample() - 1\n",
        "            return torch.tensor([[1.0, rho], [rho, 1.0]], dtype=torch.double)\n",
        "        beta = eta + (d - 2) / 2\n",
        "        r12 = 2 * torch.distributions.Beta(beta, beta).sample() - 1\n",
        "        R = torch.tensor([[1.0, r12], [r12, 1.0]], dtype=torch.double)\n",
        "        for m in range(2, d):\n",
        "            beta -= 0.5\n",
        "            y = torch.distributions.Beta(m / 2, beta).sample()\n",
        "            z = torch.randn(m, dtype=torch.double)\n",
        "            z = z / torch.linalg.norm(z)\n",
        "            w = torch.sqrt(y) * z\n",
        "            q = torch.mv(torch.linalg.cholesky(R), w)\n",
        "            R = torch.block_diag(R, torch.ones(1, dtype=torch.double))\n",
        "            R[:-1, -1] = q\n",
        "            R[-1, :-1] = q\n",
        "        return R\n",
        "    low, high = rangeVar\n",
        "    variances = (high - low) * torch.rand(dim, dtype=torch.double) + low\n",
        "    D = torch.diag(torch.sqrt(variances))\n",
        "    Sigma = D @ _rcor_onion(dim) @ D\n",
        "    return Sigma.to(torch.get_default_dtype())\n",
        "\n",
        "def KL(Sigma1_1, Sigma2_1, Sigma3_1,\n",
        "       Sigma1_2, Sigma2_2, Sigma3_2):\n",
        "\n",
        "    p1 = Sigma1_1.shape[0]\n",
        "    p2 = Sigma2_1.shape[0]\n",
        "    p3 = Sigma3_1.shape[0]\n",
        "\n",
        "\n",
        "    A3 = torch.linalg.solve(Sigma3_2, Sigma3_1)\n",
        "    A2 = torch.linalg.solve(Sigma2_2, Sigma2_1)\n",
        "    A1 = torch.linalg.solve(Sigma1_2, Sigma1_1)\n",
        "\n",
        "    tr3 = torch.trace(A3)\n",
        "    tr2 = torch.trace(A2)\n",
        "    tr1 = torch.trace(A1)\n",
        "\n",
        "    det3 = torch.det(A3)\n",
        "    det2 = torch.det(A2)\n",
        "    det1 = torch.det(A1)\n",
        "\n",
        "    val = 0.5 * (\n",
        "        (tr3 * tr2 * tr1)\n",
        "        - (p1 * p2) * math.log(det3)\n",
        "        - (p1 * p3) * math.log(det2)\n",
        "        - (p2 * p3) * math.log(det1)\n",
        "        - (p1 * p2 * p3)\n",
        "    )\n",
        "    return val.item()\n",
        "\n",
        "\n",
        "\n",
        "def run_tmcd_check(n,\n",
        "                   p1, p2, p3,\n",
        "                   outlier_fraction,\n",
        "                   method_outliers,\n",
        "                   infection_fraction=None,\n",
        "                   infection_range=None,\n",
        "                   outlier_shift=None,\n",
        "                   alpha=0.6,\n",
        "                   nSubsets=100,\n",
        "                   nBest=10,\n",
        "                   maxIterCshort=2,\n",
        "                   maxIterFFshort=2,\n",
        "                   maxIterCfull=100,\n",
        "                   maxIterFFfull=100,\n",
        "                   tolC=1e-4,\n",
        "                   tolFF=1e-3,\n",
        "                   beta=0.99,\n",
        "                   seed=None):\n",
        "\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_runs = 1\n",
        "\n",
        "    Sigma1_true = genPositiveDefMat(p1, rangeVar=(0.1, 1.0)).to(device)\n",
        "\n",
        "\n",
        "    Sigma2_true = 0.5 * torch.ones(p2, p2, device=device)\n",
        "    Sigma2_true.fill_diagonal_(0.7)\n",
        "\n",
        "\n",
        "    Sigma3_true = torch.zeros(p3, p3, device=device)\n",
        "    for i in range(p3):\n",
        "        for j in range(p3):\n",
        "            if i == j:\n",
        "                Sigma3_true[i, j] = 0.7\n",
        "            else:\n",
        "                Sigma3_true[i, j] = 0.5 ** abs(i - j)\n",
        "\n",
        "\n",
        "    Mu_true = torch.randn(p1, p2, p3, device=device) + 1.0\n",
        "\n",
        "    X_clean = rTensorNorm(n, Mu_true, Sigma1_true, Sigma2_true, Sigma3_true)\n",
        "\n",
        "    X_outliers = X_clean.clone()\n",
        "    n_outliers = int(math.floor(n * outlier_fraction))\n",
        "    outlier_indices = []\n",
        "\n",
        "    if n_outliers > 0:\n",
        "        outlier_indices = random.sample(range(n), n_outliers)\n",
        "\n",
        "        if method_outliers == \"method1\":\n",
        "\n",
        "            if outlier_shift is None:\n",
        "                raise ValueError(\"For method1, you must provide outlier_shift.\")\n",
        "            Mu_shifted = Mu_true + outlier_shift\n",
        "            X_outlier_sample = rTensorNorm(n_outliers, Mu_shifted,\n",
        "                                           Sigma1_true, Sigma2_true, Sigma3_true)\n",
        "            for i, idx in enumerate(outlier_indices):\n",
        "                X_outliers[idx] = X_outlier_sample[i]\n",
        "\n",
        "        elif method_outliers == \"method2\":\n",
        "\n",
        "            if (infection_fraction is None) or (infection_range is None):\n",
        "                raise ValueError(\"For method2, must provide infection_fraction and infection_range.\")\n",
        "            total_cells = p1 * p2 * p3\n",
        "            cells_to_infect = int(math.floor(infection_fraction * total_cells))\n",
        "\n",
        "            for idx in outlier_indices:\n",
        "\n",
        "                infected_cells_lin = random.sample(range(total_cells), cells_to_infect)\n",
        "                slice_ijk = X_outliers[idx]\n",
        "                for lin in infected_cells_lin:\n",
        "                    i = lin // (p2 * p3)\n",
        "                    rem = lin % (p2 * p3)\n",
        "                    j = rem // p3\n",
        "                    k = rem % p3\n",
        "\n",
        "                    val = random.uniform(infection_range[0], infection_range[1])\n",
        "                    slice_ijk[i, j, k] += val\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Unknown method_outliers. Must be 'method1' or 'method2'.\")\n",
        "\n",
        "\n",
        "\n",
        "    elapsed = []\n",
        "\n",
        "    final_tmcd_result = None\n",
        "\n",
        "\n",
        "    rng_state = torch.get_rng_state().clone()\n",
        "    np_rng_state = np.random.get_state()\n",
        "    py_rng_state = random.getstate()\n",
        "\n",
        "    for i in range(n_runs):\n",
        "\n",
        "        torch.set_rng_state(rng_state.clone())\n",
        "        np.random.set_state(np_rng_state)\n",
        "        random.setstate(py_rng_state)\n",
        "\n",
        "        start_time = time.time()\n",
        "        tmcd_result = tmcd(\n",
        "            X_outliers,\n",
        "            alpha=alpha,\n",
        "            nSubsets=nSubsets,\n",
        "            nBest=nBest,\n",
        "            maxIterCshort=maxIterCshort,\n",
        "            maxIterFFshort=maxIterFFshort,\n",
        "            maxIterCfull=maxIterCfull,\n",
        "            maxIterFFfull=maxIterFFfull,\n",
        "            tolC=tolC,\n",
        "            tolFF=tolFF,\n",
        "            beta=beta\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        elapsed.append(end_time - start_time)\n",
        "\n",
        "        final_tmcd_result = tmcd_result\n",
        "\n",
        "    elapsed_sorted = sorted(elapsed)\n",
        "    print(\"\\nElapsed times (seconds) from fastest to slowest:\")\n",
        "    print(\" - \".join(f\"{e:.3f}\" for e in elapsed_sorted))\n",
        "\n",
        "\n",
        "    s1_true = Sigma1_true[0, 0].item()\n",
        "    s2_true = Sigma2_true[0, 0].item()\n",
        "    Sigma1_true_scaled = Sigma1_true / s1_true\n",
        "    Sigma2_true_scaled = Sigma2_true / s2_true\n",
        "    Sigma3_true_scaled = Sigma3_true * (s1_true * s2_true)\n",
        "\n",
        "    S1_est = final_tmcd_result[\"Sigma1\"]\n",
        "    S2_est = final_tmcd_result[\"Sigma2\"]\n",
        "    S3_est = final_tmcd_result[\"Sigma3\"]\n",
        "    Mu_est = final_tmcd_result[\"M\"]\n",
        "\n",
        "    Mu_diff = Mu_est - Mu_true\n",
        "    Mu_diff_norm = Mu_diff.norm().item()\n",
        "\n",
        "    Sigma1_diff = S1_est - Sigma1_true_scaled\n",
        "    Sigma2_diff = S2_est - Sigma2_true_scaled\n",
        "    Sigma3_diff = S3_est - Sigma3_true_scaled\n",
        "\n",
        "    Sigma1_diff_norm = Sigma1_diff.norm().item()\n",
        "    Sigma2_diff_norm = Sigma2_diff.norm().item()\n",
        "    Sigma3_diff_norm = Sigma3_diff.norm().item()\n",
        "\n",
        "    print(\"\\nDifference norms:\")\n",
        "    print(f\"  Mu diff norm        : {Mu_diff_norm:.4f}\")\n",
        "    print(f\"  Sigma1 diff norm    : {Sigma1_diff_norm:.4f}\")\n",
        "    print(f\"  Sigma2 diff norm    : {Sigma2_diff_norm:.4f}\")\n",
        "    print(f\"  Sigma3 diff norm    : {Sigma3_diff_norm:.4f}\")\n",
        "\n",
        "\n",
        "    kl_value = KL(Sigma1_true_scaled, Sigma2_true_scaled, Sigma3_true_scaled,\n",
        "                  S1_est, S2_est, S3_est)\n",
        "    print(f\"\\nKL divergence         : {kl_value:.4f}\")\n",
        "\n",
        "\n",
        "    flagged_outliers = final_tmcd_result[\"outliers\"].cpu().numpy()\n",
        "    actual_outliers  = np.array(outlier_indices, dtype=int)\n",
        "\n",
        "    n_flagged = flagged_outliers.size\n",
        "    flagged_set = set(flagged_outliers.tolist())\n",
        "    actual_set  = set(actual_outliers.tolist())\n",
        "    n_correct   = len(flagged_set.intersection(actual_set))\n",
        "\n",
        "    if n_flagged == 0:\n",
        "        precision = 0.0\n",
        "    else:\n",
        "        precision = n_correct / n_flagged\n",
        "\n",
        "    if actual_outliers.size == 0:\n",
        "        recall = 1.0\n",
        "    else:\n",
        "        recall = n_correct / actual_outliers.size\n",
        "\n",
        "    if (precision + recall) == 0:\n",
        "        F_score = 0.0\n",
        "    else:\n",
        "        F_score = 2.0 * precision * recall / (precision + recall)\n",
        "\n",
        "    print(\"\\nOutlier detection summary:\")\n",
        "    print(f\"  Actual number of outliers : {actual_outliers.size}\")\n",
        "    print(f\"  Flagged as outliers       : {n_flagged}\")\n",
        "    print(f\"  Correctly flagged         : {n_correct}\")\n",
        "    print(f\"  Precision                 : {precision:.3f}\")\n",
        "    print(f\"  Recall                    : {recall:.3f}\")\n",
        "    print(f\"  F-score                   : {F_score:.3f}\")\n",
        "\n",
        "\n",
        "    M_full = X_outliers.mean(dim=0)\n",
        "    C1_full = X_outliers - M_full\n",
        "    C2_full = C1_full.permute(0, 2, 3, 1).contiguous()\n",
        "    C3_full = C1_full.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "    mle_full = flipFlopMLE(\n",
        "        C1_full, C2_full, C3_full,\n",
        "        torch.eye(p1, device=device),\n",
        "        torch.eye(p2, device=device),\n",
        "        torch.eye(p3, device=device),\n",
        "        torch.eye(p2, device=device),\n",
        "        torch.eye(p3, device=device),\n",
        "        maxIter=maxIterFFfull,\n",
        "        tol=tolFF\n",
        "    )\n",
        "    S1_full = mle_full[\"Sigma1\"]\n",
        "    S2_full = mle_full[\"Sigma2\"]\n",
        "    S3_full = mle_full[\"Sigma3\"]\n",
        "\n",
        "    kl_full = KL(Sigma1_true_scaled, Sigma2_true_scaled, Sigma3_true_scaled,\n",
        "                 S1_full, S2_full, S3_full)\n",
        "    print(f\"\\nKL divergence (True vs. full-sample MLE): {kl_full:.4f}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"Sigma1_true_scaled\": Sigma1_true_scaled,\n",
        "        \"Sigma2_true_scaled\": Sigma2_true_scaled,\n",
        "        \"Sigma3_true_scaled\": Sigma3_true_scaled,\n",
        "        \"Sigma1_est\": S1_est,\n",
        "        \"Sigma2_est\": S2_est,\n",
        "        \"Sigma3_est\": S3_est,\n",
        "        \"Mu_true\": Mu_true,\n",
        "        \"Mu_est\": Mu_est,\n",
        "        \"outliers_flagged\": flagged_outliers,\n",
        "        \"outliers_actual\": actual_outliers,\n",
        "        \"Mu_diff_norm\": Mu_diff_norm,\n",
        "        \"Sigma1_diff_norm\": Sigma1_diff_norm,\n",
        "        \"Sigma2_diff_norm\": Sigma2_diff_norm,\n",
        "        \"Sigma3_diff_norm\": Sigma3_diff_norm,\n",
        "        \"KL_value\": kl_value,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"F_score\": F_score\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def compareSigmas(res, digits=3, col_gap=6):\n",
        "\n",
        "\n",
        "    def format_cell(val, w):\n",
        "        return f\"{val:.{digits}f}\".rjust(w)\n",
        "\n",
        "    def printSigma(true_mat, est_mat, name):\n",
        "        print(f\"\\n{name} (scaled): Left = True, Right = Estimated\")\n",
        "        p = true_mat.shape[0]\n",
        "        all_vals = torch.cat((true_mat.flatten(), est_mat.flatten()))\n",
        "        test_strs = [f\"{v:.{digits}f}\" for v in all_vals]\n",
        "        cell_width = max(len(s) for s in test_strs)\n",
        "        gap = \" \" * col_gap\n",
        "\n",
        "        for i in range(p):\n",
        "            row_strs = []\n",
        "            for j in range(p):\n",
        "                left_str = format_cell(true_mat[i, j].item(), cell_width)\n",
        "                right_str = format_cell(est_mat[i, j].item(), cell_width)\n",
        "                row_strs.append(f\"{left_str} | {right_str}\")\n",
        "            print(gap.join(row_strs))\n",
        "\n",
        "    printSigma(res[\"Sigma1_true_scaled\"], res[\"Sigma1_est\"], \"Sigma1\")\n",
        "    printSigma(res[\"Sigma2_true_scaled\"], res[\"Sigma2_est\"], \"Sigma2\")\n",
        "    printSigma(res[\"Sigma3_true_scaled\"], res[\"Sigma3_est\"], \"Sigma3\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P2RBGkHzeH6X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch version :\", torch.__version__)\n",
        "print(\"CUDA version    :\", torch.version.cuda)\n",
        "print(\"CUDA available  :\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4QgQ0JumEKZ",
        "outputId": "6ed5a509-a27c-40ac-c64a-644477012c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version : 2.6.0+cu124\n",
            "CUDA version    : 12.4\n",
            "CUDA available  : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 101\n",
        "params = dict(\n",
        "                n=350,\n",
        "                p1=200,\n",
        "                p2=250,\n",
        "                p3=50,\n",
        "                outlier_shift=0.5,\n",
        "                outlier_fraction=0.25,\n",
        "                method_outliers=\"method1\",\n",
        "                alpha=0.6,\n",
        "                nSubsets=500,\n",
        "                nBest=10,\n",
        "                maxIterCshort=2,\n",
        "                maxIterFFshort=2,\n",
        "                maxIterCfull=100,\n",
        "                maxIterFFfull=100,\n",
        "                tolC=1e-4,\n",
        "                tolFF=1e-3,\n",
        "                beta=0.99,\n",
        "                seed=seed\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- Running TMCD Check ---\")\n",
        "res = run_tmcd_check(**params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xknKcGJCh0az",
        "outputId": "ab5c50c6-46eb-4338-a2ef-8de62c693863"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running TMCD Check ---\n",
            "\n",
            "Elapsed times (seconds) from fastest to slowest:\n",
            "444.616\n",
            "\n",
            "Difference norms:\n",
            "  Mu diff norm        : 57.3175\n",
            "  Sigma1 diff norm    : 0.1113\n",
            "  Sigma2 diff norm    : 0.1280\n",
            "  Sigma3 diff norm    : 0.0195\n",
            "\n",
            "KL divergence         : 138.3750\n",
            "\n",
            "Outlier detection summary:\n",
            "  Actual number of outliers : 87\n",
            "  Flagged as outliers       : 140\n",
            "  Correctly flagged         : 87\n",
            "  Precision                 : 0.621\n",
            "  Recall                    : 1.000\n",
            "  F-score                   : 0.767\n",
            "\n",
            "KL divergence (True vs. full-sample MLE): -inf\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "for var in list(globals().values()):\n",
        "    if hasattr(var, 'iterator') and hasattr(var, 'num_workers'):\n",
        "        var._iterator._shutdown_workers()\n",
        "for k in list(globals().keys()):\n",
        "    obj = globals()[k]\n",
        "    if torch.is_tensor(obj) or isinstance(obj, torch.nn.Module):\n",
        "        del globals()[k]\n",
        "\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "print(\"allocated :\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
        "print(\"reserved  :\", torch.cuda.memory_reserved()  / 1024**2, \"MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CUUocRahRK5",
        "outputId": "04af9073-8ec6-4205-a190-2adb4f667592"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "allocated : 8.125 MB\n",
            "reserved  : 20.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del tensors_and_models\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "H4_70Ddy4nYJ",
        "outputId": "5b5b6832-242e-475d-aaa4-b3c35e7e173c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tensors_and_models' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3cef4a5c7393>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtensors_and_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tensors_and_models' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, importlib.util, urllib.request\n",
        "!pip install rdata tqdm\n",
        "\n",
        "import rdata, torch, numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- load RData ----------\n",
        "url  = \"https://wis.kuleuven.be/stat/robust/Programs/DO/do-video-data-rdata\"\n",
        "fbin = Path(\"do-video-data.rdata\")\n",
        "if not fbin.exists():\n",
        "    urllib.request.urlretrieve(url, fbin)\n",
        "\n",
        "video_py = rdata.conversion.convert(rdata.parser.parse_file(fbin))[\"Video\"]\n",
        "print(\"Video shape:\", video_py.shape)      # (633, 128, 160, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxAbymgPXvJB",
        "outputId": "4a488244-9010-410a-ce2b-3ef5159e4350"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdata\n",
            "  Downloading rdata-0.11.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdata) (2.0.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (from rdata) (2025.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from rdata) (2.2.2)\n",
            "Requirement already satisfied: typing-extensions>4.4 in /usr/local/lib/python3.11/dist-packages (from rdata) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->rdata) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->rdata) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->rdata) (2025.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray->rdata) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->rdata) (1.17.0)\n",
            "Downloading rdata-0.11.2-py3-none-any.whl (46 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdata\n",
            "Successfully installed rdata-0.11.2\n",
            "Video shape: (633, 128, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_full = torch.tensor(video_py, dtype=torch.float32, device=device).contiguous()\n",
        "n, p1, p2, p3 = X_full.shape\n",
        "assert p3 == 3, \"RGB expected\"\n",
        "\n",
        "seed = 102\n",
        "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "start = time.perf_counter()\n",
        "tmcd_res = tmcd(\n",
        "    X_full,\n",
        "    alpha          = 0.75,\n",
        "    nSubsets       = 10,\n",
        "    nBest          = 10,\n",
        "    maxIterCshort  = 2,\n",
        "    maxIterFFshort = 2,\n",
        "    maxIterCfull   = 25,\n",
        "    maxIterFFfull  = 100,\n",
        "    tolC           = 1e-4,\n",
        "    tolFF          = 1e-3,\n",
        "    beta           = 0.9999\n",
        ")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "elapsed = time.perf_counter() - start\n",
        "\n",
        "print(f\"TMCD done – good frames: {tmcd_res['finalGood'].numel()}\")\n",
        "print(f\"Elapsed time: {elapsed:.2f}s\")\n",
        "print(\"Outlier indices:\", sorted(tmcd_res[\"outliers\"].cpu().tolist()))\n",
        "\n",
        "# number of frames *not* flagged as outliers from index 483 onward\n",
        "start      = 483\n",
        "n_frames   = X_full.shape[0]               # 633\n",
        "outliers   = set(tmcd_res[\"outliers\"].cpu().tolist())\n",
        "\n",
        "missing = [i for i in range(start, n_frames) if i not in outliers]\n",
        "\n",
        "print(f\"From frame {start} to {n_frames-1}: \"\n",
        "      f\"{len(missing)} frames are NOT in the outlier list.\")\n",
        "print(\"Indices:\", missing)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3fQgE7IN58l",
        "outputId": "336e234f-e14a-463a-d0a3-ed47c5f1f7d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TMCD done – good frames: 474\n",
            "Elapsed time: 4.95s\n",
            "Outlier indices: [409, 410, 413, 421, 443, 447, 456, 458, 459, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632]\n",
            "From frame 483 to 632: 0 frames are NOT in the outlier list.\n",
            "Indices: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "X_full = torch.tensor(video_py, dtype=torch.float32, device=device).contiguous()\n",
        "n, p1, p2, p3 = X_full.shape\n",
        "assert p3 == 3, \"RGB expected\"\n",
        "\n",
        "seed = 102\n",
        "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "start = time.perf_counter()\n",
        "tmcd_res = tmcd(\n",
        "    X_full,\n",
        "    alpha          = 0.75,\n",
        "    nSubsets       = 500,\n",
        "    nBest          = 20,\n",
        "    maxIterCshort  = 2,\n",
        "    maxIterFFshort = 2,\n",
        "    maxIterCfull   = 100,\n",
        "    maxIterFFfull  = 100,\n",
        "    tolC           = 1e-4,\n",
        "    tolFF          = 1e-3,\n",
        "    beta           = 0.9999\n",
        ")\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.synchronize()\n",
        "elapsed = time.perf_counter() - start\n",
        "\n",
        "print(f\"TMCD done – good frames: {tmcd_res['finalGood'].numel()}\")\n",
        "print(f\"Elapsed time: {elapsed:.2f}s\")\n",
        "print(\"Outlier indices:\", sorted(tmcd_res[\"outliers\"].cpu().tolist()))\n",
        "\n",
        "# number of frames *not* flagged as outliers from index 483 onward\n",
        "start      = 483\n",
        "n_frames   = X_full.shape[0]               # 633\n",
        "outliers   = set(tmcd_res[\"outliers\"].cpu().tolist())\n",
        "\n",
        "missing = [i for i in range(start, n_frames) if i not in outliers]\n",
        "\n",
        "print(f\"From frame {start} to {n_frames-1}: \"\n",
        "      f\"{len(missing)} frames are NOT in the outlier list.\")\n",
        "print(\"Indices:\", missing)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yL1ibhA9QqZ",
        "outputId": "b11e6050-5db9-4e5f-fd4a-f05a1be6ebe9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TMCD done – good frames: 474\n",
            "Elapsed time: 67.78s\n",
            "Outlier indices: [409, 410, 413, 421, 443, 447, 450, 456, 458, 459, 483, 484, 485, 486, 487, 488, 489, 490, 491, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632]\n",
            "From frame 483 to 632: 1 frames are NOT in the outlier list.\n",
            "Indices: [492]\n"
          ]
        }
      ]
    }
  ]
}